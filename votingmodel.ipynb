{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.ensemble import BaggingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   user_id                            10000 non-null  object \n",
      " 1   subscription_duration              10000 non-null  int64  \n",
      " 2   recent_login_time                  10000 non-null  int64  \n",
      " 3   average_login_time                 10000 non-null  float64\n",
      " 4   average_time_per_learning_session  10000 non-null  float64\n",
      " 5   monthly_active_learning_days       10000 non-null  int64  \n",
      " 6   total_completed_courses            10000 non-null  int64  \n",
      " 7   recent_learning_achievement        10000 non-null  float64\n",
      " 8   abandoned_learning_sessions        10000 non-null  int64  \n",
      " 9   community_engagement_level         10000 non-null  int64  \n",
      " 10  preferred_difficulty_level         10000 non-null  object \n",
      " 11  subscription_type                  10000 non-null  object \n",
      " 12  customer_inquiry_history           10000 non-null  int64  \n",
      " 13  payment_pattern                    10000 non-null  int64  \n",
      " 14  target                             10000 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "train.describe()\n",
    "\n",
    "train.info()\n",
    "#plt.figure(figsize=(20, 20))\n",
    "#sns.heatmap(train[train.select_dtypes(exclude='object').columns].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>subscription_duration</th>\n",
       "      <th>recent_login_time</th>\n",
       "      <th>average_login_time</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "      <th>monthly_active_learning_days</th>\n",
       "      <th>total_completed_courses</th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>abandoned_learning_sessions</th>\n",
       "      <th>community_engagement_level</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>customer_inquiry_history</th>\n",
       "      <th>payment_pattern</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b919c29d</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14.946163</td>\n",
       "      <td>8.427187</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>68.360455</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a0a60abb</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>18.453224</td>\n",
       "      <td>72.646087</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>97.567322</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b9f171ae</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>16.195228</td>\n",
       "      <td>21.774492</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>94.358763</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Premium</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5dc0ba8b</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>17.628656</td>\n",
       "      <td>42.659066</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>70.153228</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65c83654</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>21.390656</td>\n",
       "      <td>30.744287</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>81.917908</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  subscription_duration  recent_login_time  average_login_time  \\\n",
       "0  b919c29d                     13                 14           14.946163   \n",
       "1  a0a60abb                     16                 18           18.453224   \n",
       "2  b9f171ae                     22                  1           16.195228   \n",
       "3  5dc0ba8b                      1                 19           17.628656   \n",
       "4  65c83654                      4                  5           21.390656   \n",
       "\n",
       "   average_time_per_learning_session  monthly_active_learning_days  \\\n",
       "0                           8.427187                            18   \n",
       "1                          72.646087                            16   \n",
       "2                          21.774492                            13   \n",
       "3                          42.659066                            19   \n",
       "4                          30.744287                            19   \n",
       "\n",
       "   total_completed_courses  recent_learning_achievement  \\\n",
       "0                       16                    68.360455   \n",
       "1                       13                    97.567322   \n",
       "2                       14                    94.358763   \n",
       "3                       18                    70.153228   \n",
       "4                       10                    81.917908   \n",
       "\n",
       "   abandoned_learning_sessions  community_engagement_level  \\\n",
       "0                            3                           4   \n",
       "1                            2                           3   \n",
       "2                            3                           4   \n",
       "3                            0                           3   \n",
       "4                            2                           4   \n",
       "\n",
       "  preferred_difficulty_level subscription_type  customer_inquiry_history  \\\n",
       "0                        Low             Basic                         4   \n",
       "1                     Medium             Basic                         1   \n",
       "2                     Medium           Premium                         0   \n",
       "3                        Low             Basic                         1   \n",
       "4                     Medium             Basic                         3   \n",
       "\n",
       "   payment_pattern  target  \n",
       "0                5       0  \n",
       "1                6       1  \n",
       "2                7       1  \n",
       "3                0       1  \n",
       "4                0       1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Abandon_compare_complete'] = train['abandoned_learning_sessions']/train['total_completed_courses']\n",
    "# test['Abandon_compare_complete'] = test['abandoned_learning_sessions']/test['total_completed_courses']\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "train.drop('abandoned_learning_sessions', axis=1, inplace=True)\n",
    "test.drop('abandoned_learning_sessions', axis=1, inplace=True)\n",
    "train.drop('average_login_time', axis=1, inplace=True)\n",
    "test.drop('average_login_time', axis=1, inplace=True)\n",
    "train.drop('payment_pattern', axis=1, inplace=True)\n",
    "test.drop('payment_pattern', axis=1, inplace=True)\n",
    "train['recent_learning_achievement'] = train['recent_learning_achievement'].apply(lambda x : train['recent_learning_achievement'].mean() if x >= 100 else x)\n",
    "\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64'] and col not in ['target']]\n",
    "#numerical_cols.remove('payment_pattern')\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object' and col not in ['user_id']]\n",
    "#categorical_cols.append('payment_pattern')\n",
    "# 데이터 스케일링을 위한 StandardScaler 인스턴스 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 수치형 데이터에 대해 스케일링 적용\n",
    "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])\n",
    "\n",
    "# 레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "# 전처리 후 학습 데이터 확인\n",
    "train.head()\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = train.drop(columns=['user_id', 'target'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "y = train['target']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, RobustScaler\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64'] and col not in ['target']]\n",
    "numerical_cols.remove('payment_pattern')\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object' and col not in ['user_id']]\n",
    "categorical_cols.append('payment_pattern')\n",
    "# 데이터 스케일링을 위한 StandardScaler 인스턴스 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 수치형 데이터에 대해 스케일링 적용\n",
    "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])\n",
    "\n",
    "# 레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "\n",
    "\n",
    "# 전처리 후 학습 데이터 확인\n",
    "train.head()\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = train.drop(columns=['user_id', 'target'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "y = train['target']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscription_duration</th>\n",
       "      <th>recent_login_time</th>\n",
       "      <th>average_login_time</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "      <th>monthly_active_learning_days</th>\n",
       "      <th>total_completed_courses</th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>abandoned_learning_sessions</th>\n",
       "      <th>community_engagement_level</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>customer_inquiry_history</th>\n",
       "      <th>payment_pattern</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.008550</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>3.740467e-03</td>\n",
       "      <td>2.875078e-01</td>\n",
       "      <td>-0.037883</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>-7.183160e-03</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>-0.056950</td>\n",
       "      <td>1.100800</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>3.502900</td>\n",
       "      <td>0.619900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.550075</td>\n",
       "      <td>0.597327</td>\n",
       "      <td>7.561871e-01</td>\n",
       "      <td>9.289761e-01</td>\n",
       "      <td>0.577687</td>\n",
       "      <td>0.726825</td>\n",
       "      <td>7.416552e-01</td>\n",
       "      <td>0.877526</td>\n",
       "      <td>0.631088</td>\n",
       "      <td>0.700492</td>\n",
       "      <td>0.490346</td>\n",
       "      <td>0.710491</td>\n",
       "      <td>2.311261</td>\n",
       "      <td>0.485435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.916667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-3.177293e+00</td>\n",
       "      <td>-6.229283e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.200000</td>\n",
       "      <td>-2.915299e+00</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-4.921302e-01</td>\n",
       "      <td>-3.698076e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-5.094894e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.237370e-16</td>\n",
       "      <td>-5.889928e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.286434e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.078698e-01</td>\n",
       "      <td>6.301924e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>4.905106e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.027718e+00</td>\n",
       "      <td>7.723635e+00</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.791309e+00</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subscription_duration  recent_login_time  average_login_time  \\\n",
       "count           10000.000000       10000.000000        1.000000e+04   \n",
       "mean               -0.008550           0.000943        3.740467e-03   \n",
       "std                 0.550075           0.597327        7.561871e-01   \n",
       "min                -0.916667          -1.000000       -3.177293e+00   \n",
       "25%                -0.500000          -0.500000       -4.921302e-01   \n",
       "50%                 0.000000           0.000000        2.237370e-16   \n",
       "75%                 0.500000           0.500000        5.078698e-01   \n",
       "max                 0.916667           1.000000        3.027718e+00   \n",
       "\n",
       "       average_time_per_learning_session  monthly_active_learning_days  \\\n",
       "count                       1.000000e+04                  10000.000000   \n",
       "mean                        2.875078e-01                     -0.037883   \n",
       "std                         9.289761e-01                      0.577687   \n",
       "min                        -6.229283e-01                     -1.000000   \n",
       "25%                        -3.698076e-01                     -0.500000   \n",
       "50%                        -5.889928e-17                      0.000000   \n",
       "75%                         6.301924e-01                      0.500000   \n",
       "max                         7.723635e+00                      0.916667   \n",
       "\n",
       "       total_completed_courses  recent_learning_achievement  \\\n",
       "count             10000.000000                 1.000000e+04   \n",
       "mean                  0.045500                -7.183160e-03   \n",
       "std                   0.726825                 7.416552e-01   \n",
       "min                  -2.200000                -2.915299e+00   \n",
       "25%                  -0.400000                -5.094894e-01   \n",
       "50%                   0.000000                 5.286434e-16   \n",
       "75%                   0.600000                 4.905106e-01   \n",
       "max                   3.000000                 2.791309e+00   \n",
       "\n",
       "       abandoned_learning_sessions  community_engagement_level  \\\n",
       "count                 10000.000000                10000.000000   \n",
       "mean                      0.021800                   -0.056950   \n",
       "std                       0.877526                    0.631088   \n",
       "min                      -1.500000                   -1.500000   \n",
       "25%                      -0.500000                   -0.500000   \n",
       "50%                       0.000000                    0.000000   \n",
       "75%                       0.500000                    0.500000   \n",
       "max                       4.500000                    0.500000   \n",
       "\n",
       "       preferred_difficulty_level  subscription_type  \\\n",
       "count                10000.000000       10000.000000   \n",
       "mean                     1.100800           0.402100   \n",
       "std                      0.700492           0.490346   \n",
       "min                      0.000000           0.000000   \n",
       "25%                      1.000000           0.000000   \n",
       "50%                      1.000000           0.000000   \n",
       "75%                      2.000000           1.000000   \n",
       "max                      2.000000           1.000000   \n",
       "\n",
       "       customer_inquiry_history  payment_pattern        target  \n",
       "count              10000.000000     10000.000000  10000.000000  \n",
       "mean                   0.005250         3.502900      0.619900  \n",
       "std                    0.710491         2.311261      0.485435  \n",
       "min                   -1.000000         0.000000      0.000000  \n",
       "25%                   -0.500000         1.000000      0.000000  \n",
       "50%                    0.000000         4.000000      1.000000  \n",
       "75%                    0.500000         6.000000      1.000000  \n",
       "max                    4.000000         7.000000      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscription_duration</th>\n",
       "      <th>recent_login_time</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "      <th>monthly_active_learning_days</th>\n",
       "      <th>total_completed_courses</th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>community_engagement_level</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>customer_inquiry_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>-0.135958</td>\n",
       "      <td>-1.436615</td>\n",
       "      <td>-0.345056</td>\n",
       "      <td>-0.511462</td>\n",
       "      <td>0.762945</td>\n",
       "      <td>-1.374810</td>\n",
       "      <td>0.882568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.711163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.318548</td>\n",
       "      <td>0.476767</td>\n",
       "      <td>2.338099</td>\n",
       "      <td>-0.078680</td>\n",
       "      <td>0.487762</td>\n",
       "      <td>1.159508</td>\n",
       "      <td>0.882568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.414937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0.167046</td>\n",
       "      <td>1.433458</td>\n",
       "      <td>-0.946320</td>\n",
       "      <td>0.209842</td>\n",
       "      <td>0.762945</td>\n",
       "      <td>-1.050296</td>\n",
       "      <td>0.090246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.414937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>1.076059</td>\n",
       "      <td>-1.077856</td>\n",
       "      <td>0.613642</td>\n",
       "      <td>-0.799984</td>\n",
       "      <td>-0.612970</td>\n",
       "      <td>0.126036</td>\n",
       "      <td>0.090246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.711163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>1.227561</td>\n",
       "      <td>-1.436615</td>\n",
       "      <td>0.393265</td>\n",
       "      <td>0.209842</td>\n",
       "      <td>-0.888154</td>\n",
       "      <td>0.712627</td>\n",
       "      <td>0.090246</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.414937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subscription_duration  recent_login_time  \\\n",
       "9254              -0.135958          -1.436615   \n",
       "1561               0.318548           0.476767   \n",
       "1670               0.167046           1.433458   \n",
       "6087               1.076059          -1.077856   \n",
       "6669               1.227561          -1.436615   \n",
       "\n",
       "      average_time_per_learning_session  monthly_active_learning_days  \\\n",
       "9254                          -0.345056                     -0.511462   \n",
       "1561                           2.338099                     -0.078680   \n",
       "1670                          -0.946320                      0.209842   \n",
       "6087                           0.613642                     -0.799984   \n",
       "6669                           0.393265                      0.209842   \n",
       "\n",
       "      total_completed_courses  recent_learning_achievement  \\\n",
       "9254                 0.762945                    -1.374810   \n",
       "1561                 0.487762                     1.159508   \n",
       "1670                 0.762945                    -1.050296   \n",
       "6087                -0.612970                     0.126036   \n",
       "6669                -0.888154                     0.712627   \n",
       "\n",
       "      community_engagement_level  preferred_difficulty_level  \\\n",
       "9254                    0.882568                           1   \n",
       "1561                    0.882568                           1   \n",
       "1670                    0.090246                           1   \n",
       "6087                    0.090246                           1   \n",
       "6669                    0.090246                           2   \n",
       "\n",
       "      subscription_type  customer_inquiry_history  \n",
       "9254                  0                 -0.711163  \n",
       "1561                  0                 -1.414937  \n",
       "1670                  1                 -1.414937  \n",
       "6087                  1                 -0.711163  \n",
       "6669                  1                 -1.414937  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>104.157237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>103.630210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>100.135640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>103.049387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>105.318001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>101.023020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>101.160898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>101.766371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>101.905012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>102.324982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>101.570754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>101.200329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>101.661920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>106.102230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>103.178349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>101.066834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>102.660934</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>106.385512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>100.200730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>111.219647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>101.727536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>100.188238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>100.300376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>101.150779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>100.383001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>102.288523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>105.074082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>100.082805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>100.650734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>100.144342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>100.538566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5220</th>\n",
       "      <td>101.535255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>107.135153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>104.585023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5617</th>\n",
       "      <td>100.004153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>112.643828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>105.393308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6281</th>\n",
       "      <td>102.306401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>100.441425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>100.916931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>108.127099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>103.762162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7846</th>\n",
       "      <td>101.203933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7861</th>\n",
       "      <td>106.942927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7922</th>\n",
       "      <td>101.203661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>104.812784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>101.085176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>102.003670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8394</th>\n",
       "      <td>109.686851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8549</th>\n",
       "      <td>101.385671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8917</th>\n",
       "      <td>100.265149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9033</th>\n",
       "      <td>100.773346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>102.769433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>100.113689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9681</th>\n",
       "      <td>100.766278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9683</th>\n",
       "      <td>101.390814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>103.087897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>100.853522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recent_learning_achievement  target\n",
       "37                     104.157237       0\n",
       "243                    103.630210       1\n",
       "328                    100.135640       1\n",
       "333                    103.049387       0\n",
       "547                    105.318001       1\n",
       "687                    101.023020       1\n",
       "791                    101.160898       1\n",
       "890                    101.766371       1\n",
       "905                    101.905012       1\n",
       "1149                   102.324982       0\n",
       "1321                   101.570754       1\n",
       "1439                   101.200329       0\n",
       "1457                   101.661920       1\n",
       "1591                   106.102230       1\n",
       "1743                   103.178349       1\n",
       "1901                   101.066834       0\n",
       "2188                   102.660934       1\n",
       "2274                   106.385512       0\n",
       "2514                   100.200730       0\n",
       "2561                   111.219647       1\n",
       "2714                   101.727536       0\n",
       "2958                   100.188238       1\n",
       "3215                   100.300376       0\n",
       "3410                   101.150779       1\n",
       "4069                   100.383001       1\n",
       "4134                   102.288523       0\n",
       "4289                   105.074082       0\n",
       "4580                   100.082805       1\n",
       "4632                   100.650734       0\n",
       "4846                   100.144342       1\n",
       "5061                   100.538566       1\n",
       "5220                   101.535255       0\n",
       "5390                   107.135153       0\n",
       "5394                   104.585023       1\n",
       "5617                   100.004153       1\n",
       "5843                   112.643828       1\n",
       "6099                   105.393308       1\n",
       "6281                   102.306401       1\n",
       "6643                   100.441425       1\n",
       "6806                   100.916931       1\n",
       "7148                   108.127099       1\n",
       "7506                   103.762162       0\n",
       "7846                   101.203933       0\n",
       "7861                   106.942927       0\n",
       "7922                   101.203661       1\n",
       "7981                   104.812784       0\n",
       "8314                   101.085176       0\n",
       "8322                   102.003670       1\n",
       "8394                   109.686851       1\n",
       "8549                   101.385671       1\n",
       "8917                   100.265149       1\n",
       "9033                   100.773346       0\n",
       "9231                   102.769433       0\n",
       "9272                   100.113689       1\n",
       "9681                   100.766278       1\n",
       "9683                   101.390814       1\n",
       "9719                   103.087897       1\n",
       "9727                   100.853522       1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train[train['recent_learning_achievement']> 100][['recent_learning_achievement', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.04558435741137"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "qu25 = np.quantile(train['average_time_per_learning_session'], 0.25)\n",
    "qu75 = np.quantile(train['average_time_per_learning_session'], 0.75)\n",
    "\n",
    "qu75 + (qu75-qu25)*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop 3개적용한 모델 가중치 조합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.1, 0.8),\n",
       " (0.1, 0.2, 0.7000000000000001),\n",
       " (0.1, 0.30000000000000004, 0.6000000000000001),\n",
       " (0.1, 0.4, 0.5),\n",
       " (0.1, 0.5, 0.4),\n",
       " (0.1, 0.6000000000000001, 0.30000000000000004),\n",
       " (0.1, 0.7000000000000001, 0.2),\n",
       " (0.1, 0.8, 0.1),\n",
       " (0.2, 0.1, 0.7000000000000001),\n",
       " (0.2, 0.2, 0.6000000000000001),\n",
       " (0.2, 0.30000000000000004, 0.5),\n",
       " (0.2, 0.4, 0.4),\n",
       " (0.2, 0.5, 0.30000000000000004),\n",
       " (0.2, 0.6000000000000001, 0.2),\n",
       " (0.2, 0.7000000000000001, 0.1),\n",
       " (0.30000000000000004, 0.1, 0.6000000000000001),\n",
       " (0.30000000000000004, 0.2, 0.5),\n",
       " (0.30000000000000004, 0.30000000000000004, 0.4),\n",
       " (0.30000000000000004, 0.4, 0.30000000000000004),\n",
       " (0.30000000000000004, 0.5, 0.2),\n",
       " (0.30000000000000004, 0.6000000000000001, 0.1),\n",
       " (0.4, 0.1, 0.5),\n",
       " (0.4, 0.2, 0.4),\n",
       " (0.4, 0.30000000000000004, 0.30000000000000004),\n",
       " (0.4, 0.4, 0.2),\n",
       " (0.4, 0.5, 0.1),\n",
       " (0.5, 0.1, 0.4),\n",
       " (0.5, 0.2, 0.30000000000000004),\n",
       " (0.5, 0.30000000000000004, 0.2),\n",
       " (0.5, 0.4, 0.1),\n",
       " (0.6000000000000001, 0.1, 0.30000000000000004),\n",
       " (0.6000000000000001, 0.2, 0.2),\n",
       " (0.6000000000000001, 0.30000000000000004, 0.1),\n",
       " (0.7000000000000001, 0.1, 0.2),\n",
       " (0.7000000000000001, 0.2, 0.1),\n",
       " (0.8, 0.1, 0.1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_to_test = [(w1 * 0.1, w2 * 0.1, w3 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) for w3 in range(1, 10) if w1 + w2 + w3 == 10]\n",
    "weights_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [02:43<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.8, 0.1, 0.1), max_val : 0.5015926670223676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.38      0.38       758\n",
      "           1       0.62      0.63      0.62      1242\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.53      0.53      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "#svc = SVC(C=100, gamma=0.01, random_state=42, probability=True)\n",
    "#mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=70, learning_rate_init=0.001, learning_rate='constant', max_iter=500, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=500, random_state=42, subsample=0.5)\n",
    "cat = CatBoostClassifier(depth=6, iterations=300, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "\n",
    "max_val = 0\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:23<00:00,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.9, 0.1), max_val : 0.5012418246435946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.43      0.40       758\n",
      "           1       0.62      0.58      0.60      1242\n",
      "\n",
      "    accuracy                           0.52      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.52      0.52      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "#svc = SVC(C=100, gamma=0.01, random_state=42, probability=True)\n",
    "#mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=70, learning_rate_init=0.001, learning_rate='constant', max_iter=500, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=500, random_state=42, subsample=0.5)\n",
    "cat = CatBoostClassifier(depth=6, iterations=300, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "\n",
    "max_val = 0\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                #('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 11%|█         | 1/9 [00:03<00:24,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.1, 0.9), max_val : 0.49772794493291383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.35      0.36       758\n",
      "           1       0.62      0.64      0.63      1242\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.53      0.53      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:27<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "#svc = SVC(C=100, gamma=0.01, random_state=42, probability=True)\n",
    "#mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=70, learning_rate_init=0.001, learning_rate='constant', max_iter=500, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=500, random_state=42, subsample=0.5)\n",
    "cat = CatBoostClassifier(depth=6, iterations=300, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "\n",
    "max_val = 0\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [#('cat', cat),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 89%|████████▉ | 8/9 [00:28<00:03,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.8, 0.2), max_val : 0.5021152073288642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.37      0.37       758\n",
      "           1       0.62      0.64      0.63      1242\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.54      0.53      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:31<00:00,  3.54s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "#svc = SVC(C=100, gamma=0.01, random_state=42, probability=True)\n",
    "#mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=70, learning_rate_init=0.001, learning_rate='constant', max_iter=500, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=500, random_state=42, subsample=0.5)\n",
    "cat = CatBoostClassifier(depth=6, iterations=300, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "\n",
    "max_val = 0\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                ('mp', mp)],\n",
    "                                #('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop 안한거 가중치 조합 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 22%|██▏       | 8/36 [04:07<14:25, 30.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.1, 0.8, 0.1), max_val : 0.5133204956370679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36       758\n",
      "           1       0.63      0.70      0.67      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.52      0.52      0.51      2000\n",
      "weighted avg       0.54      0.56      0.55      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [18:49<00:00, 31.37s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "## standard scaler\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1, w3 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) for w3 in range(1, 10) if w1 + w2 + w3 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('svc', svc),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  6%|▌         | 2/36 [00:50<14:17, 25.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.1, 0.2, 0.7000000000000001), max_val : 0.5025363110806268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.36      0.37       758\n",
      "           1       0.62      0.65      0.64      1242\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.54      0.53      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [14:59<00:00, 24.97s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "## minmax scaler\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1, w3 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) for w3 in range(1, 10) if w1 + w2 + w3 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('svc', svc),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:47<00:00,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (9.5, 0.5), max_val : 0.5195075306695726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.36      0.38       758\n",
      "           1       0.64      0.68      0.66      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.55      0.56      0.55      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.5, w2 * 0.5) for w1 in range(1, 20) for w2 in range(1, 20) if w1 + w2 == 20]\n",
    "weights_to_test\n",
    "\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "#svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [#('svc', svc),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "# min : 0.5016342043444918\n",
    "# sta : 0.5168004757656854\n",
    "#  (0.9, 0.1), max_val : 0.5168004757656854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 44%|████▍     | 4/9 [01:24<01:45, 21.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.4, 0.6000000000000001), max_val : 0.5028545248361532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.35      0.37       758\n",
      "           1       0.62      0.66      0.64      1242\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.54      0.54      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:09<00:00, 21.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('svc', svc),\n",
    "                                #('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "\n",
    "# min : 0.5022550341101697\n",
    "# sta : 0.5028545248361532\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 11%|█         | 1/9 [00:20<02:44, 20.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.1, 0.9), max_val : 0.3943883380974001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.02      0.03       758\n",
      "           1       0.62      0.98      0.76      1242\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.46      0.50      0.39      2000\n",
      "weighted avg       0.50      0.61      0.48      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:04<00:00, 20.45s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "## minmax scaler\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('svc', svc),\n",
    "                                ('mp', mp)],\n",
    "                                #('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "\n",
    "# min : 0.3943883380974001\n",
    "# sta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop 안한거 svc -> cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 22%|██▏       | 8/36 [01:05<03:46,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.1, 0.8, 0.1), max_val : 0.514068324623177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.34      0.37       758\n",
      "           1       0.63      0.69      0.66      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.52      0.52      0.51      2000\n",
      "weighted avg       0.54      0.56      0.55      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [04:46<00:00,  7.96s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "## standard scaler\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1, w3 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) for w3 in range(1, 10) if w1 + w2 + w3 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  5%|▌         | 1/19 [00:08<02:33,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.5, 9.5), max_val : 0.5211014666267584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.36      0.38       758\n",
      "           1       0.64      0.68      0.66      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.55      0.56      0.55      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:43<00:00,  8.61s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.5, w2 * 0.5) for w1 in range(1, 20) for w2 in range(1, 20) if w1 + w2 == 20]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                ('mp', mp)],\n",
    "                                #('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=[0.2, 0.8]\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "# max_weigth : (0.2, 0.8), max_val : 0.5211014666267584\n",
    "#  0       0.41      0.36      0.38       758\n",
    "#  1       0.64      0.68      0.66      1242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 44%|████▍     | 4/9 [00:10<00:13,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.4, 0.6000000000000001), max_val : 0.5025363110806268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.36      0.37       758\n",
      "           1       0.62      0.65      0.64      1242\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.54      0.53      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:24<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                #('mp', mp)],\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "# min : 0.5016342043444918\n",
    "# sta : 0.5168004757656854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 예측 수행\n",
    "test_X = test.drop(columns=['user_id'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "test_predictions = voting_model.predict(test_X)\n",
    "\n",
    "# 제출 양식 파일(sample_submission.csv)의 'target' 컬럼에 나의 Test 데이터에 대한 예측 결과로 채우기\n",
    "sample['target'] = test_predictions\n",
    "submit_path = f'./voting_model/voting(cat, xgb)2_tuned_model_drop(aban, ave, pay)_classweight.csv'\n",
    "sample.to_csv(submit_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subscription_duration 0.10698203\n",
      "recent_login_time 0.10118902\n",
      "average_time_per_learning_session 0.10923754\n",
      "monthly_active_learning_days 0.099171825\n",
      "total_completed_courses 0.09464165\n",
      "recent_learning_achievement 0.10586606\n",
      "community_engagement_level 0.10021998\n",
      "preferred_difficulty_level 0.100718796\n",
      "subscription_type 0.08933906\n",
      "customer_inquiry_history 0.092634104\n"
     ]
    }
   ],
   "source": [
    "for i ,j in zip(X_train.columns, voting_model.feature_importances_):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_val : 0.49441982967414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.27      0.32       758\n",
      "           1       0.62      0.73      0.67      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.50      0.50      0.49      2000\n",
      "weighted avg       0.53      0.56      0.54      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001d6e9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002c77d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002df5b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000b6068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00184a0c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  target\n",
       "0  0001d6e9       0\n",
       "1  0002c77d       1\n",
       "2  0002df5b       0\n",
       "3  000b6068       1\n",
       "4  00184a0c       1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 최대 점수 !!! 0.5330428221\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# train['recent_learning_achievement'] = train['recent_learning_achievement'].apply(lambda x :  train['recent_learning_achievement'].mean() if x  > 100 else x)\n",
    "train['payment_pattern'] = train['recent_learning_achievement'].apply(lambda x: 'continuous' if x in [7, 5, 3, 1] else ('discontinuous' if x in [6, 4, 2] else 'Never'))\n",
    "test['payment_pattern'] = test['recent_learning_achievement'].apply(lambda x: 'continuous' if x in [7, 5, 3, 1] else ('discontinuous' if x in [6, 4, 2] else 'Never'))\n",
    "\n",
    "# test['recent_learning_achievement'] = test['recent_learning_achievement'].apply(lambda x :  train['recent_learning_achievement'].mean() if x  > 100 else x)\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64'] and col not in ['target']]\n",
    "#numerical_cols.remove('payment_pattern')\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object' and col not in ['user_id']]\n",
    "#categorical_cols.append('payment_pattern')\n",
    "# 데이터 스케일링을 위한 StandardScaler 인스턴스 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 수치형 데이터에 대해 스케일링 적용\n",
    "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])\n",
    "\n",
    "# 레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "# 전처리 후 학습 데이터 확인\n",
    "train.head()\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = train.drop(columns=['user_id', 'target'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "y = train['target']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "\n",
    "voting_model = VotingClassifier(estimators=\n",
    "                            [('cat', cat),\n",
    "                            ('mp', mp)],\n",
    "                            #('xgb', xgb)],\n",
    "                            voting='soft',\n",
    "                            weights=[0.2, 0.8]\n",
    "\n",
    "                            \n",
    "                            )\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터에서 성능 평가\n",
    "val_predictions = voting_model.predict(X_val)\n",
    "val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "print(f'max_val : {val_f1}')\n",
    "print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "\n",
    "test.drop(columns=['user_id'], inplace=True, axis=1) \n",
    "test_predictions = voting_model.predict(test)\n",
    "\n",
    "# 제출 양식 파일(sample_submission.csv)의 'target' 컬럼에 나의 Test 데이터에 대한 예측 결과로 채우기\n",
    "sample['target'] = test_predictions\n",
    "\n",
    "# 리더보드 제출을 위해 나의 예측 결과를 baseline_submit.csv로 저장\n",
    "#submit_path = './voting(cat, mp)_drop(None)_nopreprocessing).csv'\n",
    "#sample.to_csv(submit_path, index=False)\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>subscription_duration</th>\n",
       "      <th>recent_login_time</th>\n",
       "      <th>average_login_time</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "      <th>monthly_active_learning_days</th>\n",
       "      <th>total_completed_courses</th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>abandoned_learning_sessions</th>\n",
       "      <th>community_engagement_level</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>customer_inquiry_history</th>\n",
       "      <th>payment_pattern</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00030dc2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.636424</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.941755</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a7fac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.735407</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.752942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001daa99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.903691</td>\n",
       "      <td>0.017473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.254863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0047ee1a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.433492</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.068185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007855db</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.640182</td>\n",
       "      <td>0.045014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.733914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>ffb25bdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.481035</td>\n",
       "      <td>174.327012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.812784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>ffbed767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.962679</td>\n",
       "      <td>174.562720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.074082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>ffc7a476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.279514</td>\n",
       "      <td>176.084277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.385512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>ffcca840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.815833</td>\n",
       "      <td>177.351455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.942927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>fff20cbb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.998490</td>\n",
       "      <td>179.176060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.135153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3801 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  subscription_duration  recent_login_time  average_login_time  \\\n",
       "0     00030dc2                    6.0               27.0            3.636424   \n",
       "1     000a7fac                    NaN                NaN            4.735407   \n",
       "2     001daa99                    NaN                NaN            4.903691   \n",
       "3     0047ee1a                    NaN                NaN            5.433492   \n",
       "4     007855db                    NaN                NaN            5.640182   \n",
       "...        ...                    ...                ...                 ...   \n",
       "3796  ffb25bdf                    NaN                NaN           24.481035   \n",
       "3797  ffbed767                    NaN                NaN           24.962679   \n",
       "3798  ffc7a476                    NaN                NaN           25.279514   \n",
       "3799  ffcca840                    NaN                NaN           25.815833   \n",
       "3800  fff20cbb                    NaN                NaN           26.998490   \n",
       "\n",
       "      average_time_per_learning_session  monthly_active_learning_days  \\\n",
       "0                              0.011515                          18.0   \n",
       "1                              0.012562                           NaN   \n",
       "2                              0.017473                           NaN   \n",
       "3                              0.029555                           NaN   \n",
       "4                              0.045014                           NaN   \n",
       "...                                 ...                           ...   \n",
       "3796                         174.327012                           NaN   \n",
       "3797                         174.562720                           NaN   \n",
       "3798                         176.084277                           NaN   \n",
       "3799                         177.351455                           NaN   \n",
       "3800                         179.176060                           NaN   \n",
       "\n",
       "      total_completed_courses  recent_learning_achievement  \\\n",
       "0                        12.0                    35.941755   \n",
       "1                         NaN                    41.752942   \n",
       "2                         NaN                    42.254863   \n",
       "3                         NaN                    43.068185   \n",
       "4                         NaN                    43.733914   \n",
       "...                       ...                          ...   \n",
       "3796                      NaN                   104.812784   \n",
       "3797                      NaN                   105.074082   \n",
       "3798                      NaN                   106.385512   \n",
       "3799                      NaN                   106.942927   \n",
       "3800                      NaN                   107.135153   \n",
       "\n",
       "      abandoned_learning_sessions  community_engagement_level  \\\n",
       "0                             3.0                         5.0   \n",
       "1                             NaN                         NaN   \n",
       "2                             NaN                         NaN   \n",
       "3                             NaN                         NaN   \n",
       "4                             NaN                         NaN   \n",
       "...                           ...                         ...   \n",
       "3796                          NaN                         NaN   \n",
       "3797                          NaN                         NaN   \n",
       "3798                          NaN                         NaN   \n",
       "3799                          NaN                         NaN   \n",
       "3800                          NaN                         NaN   \n",
       "\n",
       "     preferred_difficulty_level subscription_type  customer_inquiry_history  \\\n",
       "0                           Low             Basic                       1.0   \n",
       "1                           NaN               NaN                       NaN   \n",
       "2                           NaN               NaN                       NaN   \n",
       "3                           NaN               NaN                       NaN   \n",
       "4                           NaN               NaN                       NaN   \n",
       "...                         ...               ...                       ...   \n",
       "3796                        NaN               NaN                       NaN   \n",
       "3797                        NaN               NaN                       NaN   \n",
       "3798                        NaN               NaN                       NaN   \n",
       "3799                        NaN               NaN                       NaN   \n",
       "3800                        NaN               NaN                       NaN   \n",
       "\n",
       "      payment_pattern  target  \n",
       "0                 1.0     0.0  \n",
       "1                 NaN     NaN  \n",
       "2                 NaN     NaN  \n",
       "3                 NaN     NaN  \n",
       "4                 NaN     NaN  \n",
       "...               ...     ...  \n",
       "3796              NaN     NaN  \n",
       "3797              NaN     NaN  \n",
       "3798              NaN     NaN  \n",
       "3799              NaN     NaN  \n",
       "3800              NaN     NaN  \n",
       "\n",
       "[3801 rows x 15 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "train[train['target']==0].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>subscription_duration</th>\n",
       "      <th>recent_login_time</th>\n",
       "      <th>average_login_time</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "      <th>monthly_active_learning_days</th>\n",
       "      <th>total_completed_courses</th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>abandoned_learning_sessions</th>\n",
       "      <th>community_engagement_level</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>customer_inquiry_history</th>\n",
       "      <th>payment_pattern</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00058702</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.366189</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.115562</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Basic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00076619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.375170</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.830979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00109fa1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.483285</td>\n",
       "      <td>0.037657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.430858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00153d57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.870248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0025c0af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.578543</td>\n",
       "      <td>0.060640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.970217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>ff9a0d6e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.100608</td>\n",
       "      <td>444.324058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.102230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>ffb14cb4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.271289</td>\n",
       "      <td>447.095844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.127099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>ffe5da30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.408557</td>\n",
       "      <td>470.289498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.686851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>fff3144f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.125596</td>\n",
       "      <td>490.233443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.219647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>ffff071d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.284396</td>\n",
       "      <td>503.372616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.643828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6199 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  subscription_duration  recent_login_time  average_login_time  \\\n",
       "0     00058702                    4.0                6.0            2.366189   \n",
       "1     00076619                    NaN                NaN            3.375170   \n",
       "2     00109fa1                    NaN                NaN            3.483285   \n",
       "3     00153d57                    NaN                NaN            3.970000   \n",
       "4     0025c0af                    NaN                NaN            4.578543   \n",
       "...        ...                    ...                ...                 ...   \n",
       "6194  ff9a0d6e                    NaN                NaN           25.100608   \n",
       "6195  ffb14cb4                    NaN                NaN           25.271289   \n",
       "6196  ffe5da30                    NaN                NaN           25.408557   \n",
       "6197  fff3144f                    NaN                NaN           26.125596   \n",
       "6198  ffff071d                    NaN                NaN           26.284396   \n",
       "\n",
       "      average_time_per_learning_session  monthly_active_learning_days  \\\n",
       "0                              0.013535                          24.0   \n",
       "1                              0.035931                           NaN   \n",
       "2                              0.037657                           NaN   \n",
       "3                              0.058419                           NaN   \n",
       "4                              0.060640                           NaN   \n",
       "...                                 ...                           ...   \n",
       "6194                         444.324058                           NaN   \n",
       "6195                         447.095844                           NaN   \n",
       "6196                         470.289498                           NaN   \n",
       "6197                         490.233443                           NaN   \n",
       "6198                         503.372616                           NaN   \n",
       "\n",
       "      total_completed_courses  recent_learning_achievement  \\\n",
       "0                        12.0                    36.115562   \n",
       "1                         NaN                    36.830979   \n",
       "2                         NaN                    42.430858   \n",
       "3                         NaN                    42.870248   \n",
       "4                         NaN                    42.970217   \n",
       "...                       ...                          ...   \n",
       "6194                      NaN                   106.102230   \n",
       "6195                      NaN                   108.127099   \n",
       "6196                      NaN                   109.686851   \n",
       "6197                      NaN                   111.219647   \n",
       "6198                      NaN                   112.643828   \n",
       "\n",
       "      abandoned_learning_sessions  community_engagement_level  \\\n",
       "0                             2.0                         5.0   \n",
       "1                             NaN                         NaN   \n",
       "2                             NaN                         NaN   \n",
       "3                             NaN                         NaN   \n",
       "4                             NaN                         NaN   \n",
       "...                           ...                         ...   \n",
       "6194                          NaN                         NaN   \n",
       "6195                          NaN                         NaN   \n",
       "6196                          NaN                         NaN   \n",
       "6197                          NaN                         NaN   \n",
       "6198                          NaN                         NaN   \n",
       "\n",
       "     preferred_difficulty_level subscription_type  customer_inquiry_history  \\\n",
       "0                           Low             Basic                       2.0   \n",
       "1                           NaN               NaN                       NaN   \n",
       "2                           NaN               NaN                       NaN   \n",
       "3                           NaN               NaN                       NaN   \n",
       "4                           NaN               NaN                       NaN   \n",
       "...                         ...               ...                       ...   \n",
       "6194                        NaN               NaN                       NaN   \n",
       "6195                        NaN               NaN                       NaN   \n",
       "6196                        NaN               NaN                       NaN   \n",
       "6197                        NaN               NaN                       NaN   \n",
       "6198                        NaN               NaN                       NaN   \n",
       "\n",
       "      payment_pattern  target  \n",
       "0                 0.0     1.0  \n",
       "1                 NaN     NaN  \n",
       "2                 NaN     NaN  \n",
       "3                 NaN     NaN  \n",
       "4                 NaN     NaN  \n",
       "...               ...     ...  \n",
       "6194              NaN     NaN  \n",
       "6195              NaN     NaN  \n",
       "6196              NaN     NaN  \n",
       "6197              NaN     NaN  \n",
       "6198              NaN     NaN  \n",
       "\n",
       "[6199 rows x 15 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['target']==1].mode()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dbswo\\anaconda3\\envs\\subs_predict\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:21:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_val : 0.490144904856496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.28      0.32       758\n",
      "           1       0.62      0.70      0.66      1242\n",
      "\n",
      "    accuracy                           0.55      2000\n",
      "   macro avg       0.49      0.49      0.49      2000\n",
      "weighted avg       0.52      0.55      0.53      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 현재 최대 점수 !!! 0.5330428221\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64'] and col not in ['target']]\n",
    "numerical_cols.remove('payment_pattern')\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object' and col not in ['user_id']]\n",
    "categorical_cols.append('payment_pattern')\n",
    "# 데이터 스케일링을 위한 StandardScaler 인스턴스 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 수치형 데이터에 대해 스케일링 적용\n",
    "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])\n",
    "\n",
    "# 레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "# 전처리 후 학습 데이터 확인\n",
    "train.head()\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = train.drop(columns=['user_id', 'target'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "y = train['target']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=30, max_features='sqrt', min_samples_leaf=3, min_samples_split=2, n_estimators=200, random_state=42, class_weight=weights)\n",
    "gb = GradientBoostingClassifier(learning_rate=1.0, max_depth=4, n_estimators=500, random_state=42, subsample=0.7)\n",
    "svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "bgg = BaggingClassifier()\n",
    "hgb = HistGradientBoostingClassifier(l2_regularization=0.1, learning_rate=0.5, max_depth=7, max_iter=300, random_state=42, class_weight=weights, categorical_features=[9, 10, 12])\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5, class_weights=weights)\n",
    "\n",
    "voting_model = VotingClassifier(estimators=\n",
    "                            [\n",
    "                            ('svc', svc),\n",
    "                            ('cat', cat),\n",
    "                            ('mp', mp),\n",
    "                            ('xgb', xgb)],\n",
    "                            voting='soft',\n",
    "                            weights=[1, 2, 2, 2]\n",
    "                      \n",
    "                            )\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 검증 데이터에서 성능 평가\n",
    "val_predictions = voting_model.predict(X_val)\n",
    "val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "print(f'max_val : {val_f1}')\n",
    "print(classification_report(y_val, val_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subs_predict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
