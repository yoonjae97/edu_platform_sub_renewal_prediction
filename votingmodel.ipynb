{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.ensemble import BaggingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   user_id                            10000 non-null  object \n",
      " 1   subscription_duration              10000 non-null  int64  \n",
      " 2   recent_login_time                  10000 non-null  int64  \n",
      " 3   average_login_time                 10000 non-null  float64\n",
      " 4   average_time_per_learning_session  10000 non-null  float64\n",
      " 5   monthly_active_learning_days       10000 non-null  int64  \n",
      " 6   total_completed_courses            10000 non-null  int64  \n",
      " 7   recent_learning_achievement        10000 non-null  float64\n",
      " 8   abandoned_learning_sessions        10000 non-null  int64  \n",
      " 9   community_engagement_level         10000 non-null  int64  \n",
      " 10  preferred_difficulty_level         10000 non-null  object \n",
      " 11  subscription_type                  10000 non-null  object \n",
      " 12  customer_inquiry_history           10000 non-null  int64  \n",
      " 13  payment_pattern                    10000 non-null  int64  \n",
      " 14  target                             10000 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "train.describe()\n",
    "\n",
    "train.info()\n",
    "#plt.figure(figsize=(20, 20))\n",
    "#sns.heatmap(train[train.select_dtypes(exclude='object').columns].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>subscription_duration</th>\n",
       "      <th>recent_login_time</th>\n",
       "      <th>average_login_time</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "      <th>monthly_active_learning_days</th>\n",
       "      <th>total_completed_courses</th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>abandoned_learning_sessions</th>\n",
       "      <th>community_engagement_level</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>customer_inquiry_history</th>\n",
       "      <th>payment_pattern</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b919c29d</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14.946163</td>\n",
       "      <td>8.427187</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>68.360455</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a0a60abb</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>18.453224</td>\n",
       "      <td>72.646087</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>97.567322</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b9f171ae</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>16.195228</td>\n",
       "      <td>21.774492</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>94.358763</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Premium</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5dc0ba8b</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>17.628656</td>\n",
       "      <td>42.659066</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>70.153228</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65c83654</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>21.390656</td>\n",
       "      <td>30.744287</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>81.917908</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  subscription_duration  recent_login_time  average_login_time  \\\n",
       "0  b919c29d                     13                 14           14.946163   \n",
       "1  a0a60abb                     16                 18           18.453224   \n",
       "2  b9f171ae                     22                  1           16.195228   \n",
       "3  5dc0ba8b                      1                 19           17.628656   \n",
       "4  65c83654                      4                  5           21.390656   \n",
       "\n",
       "   average_time_per_learning_session  monthly_active_learning_days  \\\n",
       "0                           8.427187                            18   \n",
       "1                          72.646087                            16   \n",
       "2                          21.774492                            13   \n",
       "3                          42.659066                            19   \n",
       "4                          30.744287                            19   \n",
       "\n",
       "   total_completed_courses  recent_learning_achievement  \\\n",
       "0                       16                    68.360455   \n",
       "1                       13                    97.567322   \n",
       "2                       14                    94.358763   \n",
       "3                       18                    70.153228   \n",
       "4                       10                    81.917908   \n",
       "\n",
       "   abandoned_learning_sessions  community_engagement_level  \\\n",
       "0                            3                           4   \n",
       "1                            2                           3   \n",
       "2                            3                           4   \n",
       "3                            0                           3   \n",
       "4                            2                           4   \n",
       "\n",
       "  preferred_difficulty_level subscription_type  customer_inquiry_history  \\\n",
       "0                        Low             Basic                         4   \n",
       "1                     Medium             Basic                         1   \n",
       "2                     Medium           Premium                         0   \n",
       "3                        Low             Basic                         1   \n",
       "4                     Medium             Basic                         3   \n",
       "\n",
       "   payment_pattern  target  \n",
       "0                5       0  \n",
       "1                6       1  \n",
       "2                7       1  \n",
       "3                0       1  \n",
       "4                0       1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Abandon_compare_complete'] = train['abandoned_learning_sessions']/train['total_completed_courses']\n",
    "# test['Abandon_compare_complete'] = test['abandoned_learning_sessions']/test['total_completed_courses']\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "train.drop('abandoned_learning_sessions', axis=1, inplace=True)\n",
    "test.drop('abandoned_learning_sessions', axis=1, inplace=True)\n",
    "train.drop('average_login_time', axis=1, inplace=True)\n",
    "test.drop('average_login_time', axis=1, inplace=True)\n",
    "train.drop('payment_pattern', axis=1, inplace=True)\n",
    "test.drop('payment_pattern', axis=1, inplace=True)\n",
    "train['recent_learning_achievement'] = train['recent_learning_achievement'].apply(lambda x : train['recent_learning_achievement'].mean() if x >= 100 else x)\n",
    "\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64'] and col not in ['target']]\n",
    "#numerical_cols.remove('payment_pattern')\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object' and col not in ['user_id']]\n",
    "#categorical_cols.append('payment_pattern')\n",
    "# 데이터 스케일링을 위한 StandardScaler 인스턴스 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 수치형 데이터에 대해 스케일링 적용\n",
    "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])\n",
    "\n",
    "# 레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "# 전처리 후 학습 데이터 확인\n",
    "train.head()\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = train.drop(columns=['user_id', 'target'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "y = train['target']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64'] and col not in ['target']]\n",
    "numerical_cols.remove('payment_pattern')\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object' and col not in ['user_id']]\n",
    "categorical_cols.append('payment_pattern')\n",
    "# 데이터 스케일링을 위한 StandardScaler 인스턴스 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 수치형 데이터에 대해 스케일링 적용\n",
    "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])\n",
    "\n",
    "# 레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "\n",
    "\n",
    "# 전처리 후 학습 데이터 확인\n",
    "train.head()\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = train.drop(columns=['user_id', 'target'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "y = train['target']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscription_duration</th>\n",
       "      <th>recent_login_time</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "      <th>monthly_active_learning_days</th>\n",
       "      <th>total_completed_courses</th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>community_engagement_level</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>customer_inquiry_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>-0.135958</td>\n",
       "      <td>-1.436615</td>\n",
       "      <td>-0.345056</td>\n",
       "      <td>-0.511462</td>\n",
       "      <td>0.762945</td>\n",
       "      <td>-1.374810</td>\n",
       "      <td>0.882568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.711163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.318548</td>\n",
       "      <td>0.476767</td>\n",
       "      <td>2.338099</td>\n",
       "      <td>-0.078680</td>\n",
       "      <td>0.487762</td>\n",
       "      <td>1.159508</td>\n",
       "      <td>0.882568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.414937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0.167046</td>\n",
       "      <td>1.433458</td>\n",
       "      <td>-0.946320</td>\n",
       "      <td>0.209842</td>\n",
       "      <td>0.762945</td>\n",
       "      <td>-1.050296</td>\n",
       "      <td>0.090246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.414937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>1.076059</td>\n",
       "      <td>-1.077856</td>\n",
       "      <td>0.613642</td>\n",
       "      <td>-0.799984</td>\n",
       "      <td>-0.612970</td>\n",
       "      <td>0.126036</td>\n",
       "      <td>0.090246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.711163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>1.227561</td>\n",
       "      <td>-1.436615</td>\n",
       "      <td>0.393265</td>\n",
       "      <td>0.209842</td>\n",
       "      <td>-0.888154</td>\n",
       "      <td>0.712627</td>\n",
       "      <td>0.090246</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.414937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subscription_duration  recent_login_time  \\\n",
       "9254              -0.135958          -1.436615   \n",
       "1561               0.318548           0.476767   \n",
       "1670               0.167046           1.433458   \n",
       "6087               1.076059          -1.077856   \n",
       "6669               1.227561          -1.436615   \n",
       "\n",
       "      average_time_per_learning_session  monthly_active_learning_days  \\\n",
       "9254                          -0.345056                     -0.511462   \n",
       "1561                           2.338099                     -0.078680   \n",
       "1670                          -0.946320                      0.209842   \n",
       "6087                           0.613642                     -0.799984   \n",
       "6669                           0.393265                      0.209842   \n",
       "\n",
       "      total_completed_courses  recent_learning_achievement  \\\n",
       "9254                 0.762945                    -1.374810   \n",
       "1561                 0.487762                     1.159508   \n",
       "1670                 0.762945                    -1.050296   \n",
       "6087                -0.612970                     0.126036   \n",
       "6669                -0.888154                     0.712627   \n",
       "\n",
       "      community_engagement_level  preferred_difficulty_level  \\\n",
       "9254                    0.882568                           1   \n",
       "1561                    0.882568                           1   \n",
       "1670                    0.090246                           1   \n",
       "6087                    0.090246                           1   \n",
       "6669                    0.090246                           2   \n",
       "\n",
       "      subscription_type  customer_inquiry_history  \n",
       "9254                  0                 -0.711163  \n",
       "1561                  0                 -1.414937  \n",
       "1670                  1                 -1.414937  \n",
       "6087                  1                 -0.711163  \n",
       "6669                  1                 -1.414937  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>104.157237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>103.630210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>100.135640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>103.049387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>105.318001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>101.023020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>101.160898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>101.766371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>101.905012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>102.324982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>101.570754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>101.200329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>101.661920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>106.102230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>103.178349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>101.066834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>102.660934</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>106.385512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>100.200730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>111.219647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>101.727536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>100.188238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>100.300376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>101.150779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>100.383001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>102.288523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>105.074082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>100.082805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>100.650734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>100.144342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>100.538566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5220</th>\n",
       "      <td>101.535255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>107.135153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>104.585023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5617</th>\n",
       "      <td>100.004153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>112.643828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>105.393308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6281</th>\n",
       "      <td>102.306401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>100.441425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>100.916931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>108.127099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>103.762162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7846</th>\n",
       "      <td>101.203933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7861</th>\n",
       "      <td>106.942927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7922</th>\n",
       "      <td>101.203661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>104.812784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>101.085176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>102.003670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8394</th>\n",
       "      <td>109.686851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8549</th>\n",
       "      <td>101.385671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8917</th>\n",
       "      <td>100.265149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9033</th>\n",
       "      <td>100.773346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>102.769433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>100.113689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9681</th>\n",
       "      <td>100.766278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9683</th>\n",
       "      <td>101.390814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>103.087897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>100.853522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recent_learning_achievement  target\n",
       "37                     104.157237       0\n",
       "243                    103.630210       1\n",
       "328                    100.135640       1\n",
       "333                    103.049387       0\n",
       "547                    105.318001       1\n",
       "687                    101.023020       1\n",
       "791                    101.160898       1\n",
       "890                    101.766371       1\n",
       "905                    101.905012       1\n",
       "1149                   102.324982       0\n",
       "1321                   101.570754       1\n",
       "1439                   101.200329       0\n",
       "1457                   101.661920       1\n",
       "1591                   106.102230       1\n",
       "1743                   103.178349       1\n",
       "1901                   101.066834       0\n",
       "2188                   102.660934       1\n",
       "2274                   106.385512       0\n",
       "2514                   100.200730       0\n",
       "2561                   111.219647       1\n",
       "2714                   101.727536       0\n",
       "2958                   100.188238       1\n",
       "3215                   100.300376       0\n",
       "3410                   101.150779       1\n",
       "4069                   100.383001       1\n",
       "4134                   102.288523       0\n",
       "4289                   105.074082       0\n",
       "4580                   100.082805       1\n",
       "4632                   100.650734       0\n",
       "4846                   100.144342       1\n",
       "5061                   100.538566       1\n",
       "5220                   101.535255       0\n",
       "5390                   107.135153       0\n",
       "5394                   104.585023       1\n",
       "5617                   100.004153       1\n",
       "5843                   112.643828       1\n",
       "6099                   105.393308       1\n",
       "6281                   102.306401       1\n",
       "6643                   100.441425       1\n",
       "6806                   100.916931       1\n",
       "7148                   108.127099       1\n",
       "7506                   103.762162       0\n",
       "7846                   101.203933       0\n",
       "7861                   106.942927       0\n",
       "7922                   101.203661       1\n",
       "7981                   104.812784       0\n",
       "8314                   101.085176       0\n",
       "8322                   102.003670       1\n",
       "8394                   109.686851       1\n",
       "8549                   101.385671       1\n",
       "8917                   100.265149       1\n",
       "9033                   100.773346       0\n",
       "9231                   102.769433       0\n",
       "9272                   100.113689       1\n",
       "9681                   100.766278       1\n",
       "9683                   101.390814       1\n",
       "9719                   103.087897       1\n",
       "9727                   100.853522       1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train[train['recent_learning_achievement']> 100][['recent_learning_achievement', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.04558435741137"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "qu25 = np.quantile(train['average_time_per_learning_session'], 0.25)\n",
    "qu75 = np.quantile(train['average_time_per_learning_session'], 0.75)\n",
    "\n",
    "qu75 + (qu75-qu25)*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop 3개적용한 모델 가중치 조합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.1, 0.8),\n",
       " (0.1, 0.2, 0.7000000000000001),\n",
       " (0.1, 0.30000000000000004, 0.6000000000000001),\n",
       " (0.1, 0.4, 0.5),\n",
       " (0.1, 0.5, 0.4),\n",
       " (0.1, 0.6000000000000001, 0.30000000000000004),\n",
       " (0.1, 0.7000000000000001, 0.2),\n",
       " (0.1, 0.8, 0.1),\n",
       " (0.2, 0.1, 0.7000000000000001),\n",
       " (0.2, 0.2, 0.6000000000000001),\n",
       " (0.2, 0.30000000000000004, 0.5),\n",
       " (0.2, 0.4, 0.4),\n",
       " (0.2, 0.5, 0.30000000000000004),\n",
       " (0.2, 0.6000000000000001, 0.2),\n",
       " (0.2, 0.7000000000000001, 0.1),\n",
       " (0.30000000000000004, 0.1, 0.6000000000000001),\n",
       " (0.30000000000000004, 0.2, 0.5),\n",
       " (0.30000000000000004, 0.30000000000000004, 0.4),\n",
       " (0.30000000000000004, 0.4, 0.30000000000000004),\n",
       " (0.30000000000000004, 0.5, 0.2),\n",
       " (0.30000000000000004, 0.6000000000000001, 0.1),\n",
       " (0.4, 0.1, 0.5),\n",
       " (0.4, 0.2, 0.4),\n",
       " (0.4, 0.30000000000000004, 0.30000000000000004),\n",
       " (0.4, 0.4, 0.2),\n",
       " (0.4, 0.5, 0.1),\n",
       " (0.5, 0.1, 0.4),\n",
       " (0.5, 0.2, 0.30000000000000004),\n",
       " (0.5, 0.30000000000000004, 0.2),\n",
       " (0.5, 0.4, 0.1),\n",
       " (0.6000000000000001, 0.1, 0.30000000000000004),\n",
       " (0.6000000000000001, 0.2, 0.2),\n",
       " (0.6000000000000001, 0.30000000000000004, 0.1),\n",
       " (0.7000000000000001, 0.1, 0.2),\n",
       " (0.7000000000000001, 0.2, 0.1),\n",
       " (0.8, 0.1, 0.1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_to_test = [(w1 * 0.1, w2 * 0.1, w3 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) for w3 in range(1, 10) if w1 + w2 + w3 == 10]\n",
    "weights_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [02:43<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.8, 0.1, 0.1), max_val : 0.5015926670223676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.38      0.38       758\n",
      "           1       0.62      0.63      0.62      1242\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.53      0.53      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "#svc = SVC(C=100, gamma=0.01, random_state=42, probability=True)\n",
    "#mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=70, learning_rate_init=0.001, learning_rate='constant', max_iter=500, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=500, random_state=42, subsample=0.5)\n",
    "cat = CatBoostClassifier(depth=6, iterations=300, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "\n",
    "max_val = 0\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:23<00:00,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.9, 0.1), max_val : 0.5012418246435946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.43      0.40       758\n",
      "           1       0.62      0.58      0.60      1242\n",
      "\n",
      "    accuracy                           0.52      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.52      0.52      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "#svc = SVC(C=100, gamma=0.01, random_state=42, probability=True)\n",
    "#mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=70, learning_rate_init=0.001, learning_rate='constant', max_iter=500, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=500, random_state=42, subsample=0.5)\n",
    "cat = CatBoostClassifier(depth=6, iterations=300, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "\n",
    "max_val = 0\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                #('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 11%|█         | 1/9 [00:03<00:24,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.1, 0.9), max_val : 0.49772794493291383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.35      0.36       758\n",
      "           1       0.62      0.64      0.63      1242\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.53      0.53      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:27<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "#svc = SVC(C=100, gamma=0.01, random_state=42, probability=True)\n",
    "#mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=70, learning_rate_init=0.001, learning_rate='constant', max_iter=500, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=500, random_state=42, subsample=0.5)\n",
    "cat = CatBoostClassifier(depth=6, iterations=300, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "\n",
    "max_val = 0\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [#('cat', cat),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 89%|████████▉ | 8/9 [00:28<00:03,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.8, 0.2), max_val : 0.5021152073288642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.37      0.37       758\n",
      "           1       0.62      0.64      0.63      1242\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.54      0.53      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:31<00:00,  3.54s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "#svc = SVC(C=100, gamma=0.01, random_state=42, probability=True)\n",
    "#mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=70, learning_rate_init=0.001, learning_rate='constant', max_iter=500, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=500, random_state=42, subsample=0.5)\n",
    "cat = CatBoostClassifier(depth=6, iterations=300, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "\n",
    "max_val = 0\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                ('mp', mp)],\n",
    "                                #('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop 안한거 가중치 조합 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 22%|██▏       | 8/36 [04:07<14:25, 30.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.1, 0.8, 0.1), max_val : 0.5133204956370679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36       758\n",
      "           1       0.63      0.70      0.67      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.52      0.52      0.51      2000\n",
      "weighted avg       0.54      0.56      0.55      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [18:49<00:00, 31.37s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "## standard scaler\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1, w3 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) for w3 in range(1, 10) if w1 + w2 + w3 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('svc', svc),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  6%|▌         | 2/36 [00:50<14:17, 25.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.1, 0.2, 0.7000000000000001), max_val : 0.5025363110806268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.36      0.37       758\n",
      "           1       0.62      0.65      0.64      1242\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.54      0.53      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [14:59<00:00, 24.97s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "## minmax scaler\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1, w3 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) for w3 in range(1, 10) if w1 + w2 + w3 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('svc', svc),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:47<00:00,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (9.5, 0.5), max_val : 0.5195075306695726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.36      0.38       758\n",
      "           1       0.64      0.68      0.66      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.55      0.56      0.55      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.5, w2 * 0.5) for w1 in range(1, 20) for w2 in range(1, 20) if w1 + w2 == 20]\n",
    "weights_to_test\n",
    "\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "#svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [#('svc', svc),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "# min : 0.5016342043444918\n",
    "# sta : 0.5168004757656854\n",
    "#  (0.9, 0.1), max_val : 0.5168004757656854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 44%|████▍     | 4/9 [01:24<01:45, 21.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.4, 0.6000000000000001), max_val : 0.5028545248361532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.35      0.37       758\n",
      "           1       0.62      0.66      0.64      1242\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.54      0.54      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:09<00:00, 21.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('svc', svc),\n",
    "                                #('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "\n",
    "# min : 0.5022550341101697\n",
    "# sta : 0.5028545248361532\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 11%|█         | 1/9 [00:20<02:44, 20.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.1, 0.9), max_val : 0.3943883380974001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.02      0.03       758\n",
      "           1       0.62      0.98      0.76      1242\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.46      0.50      0.39      2000\n",
      "weighted avg       0.50      0.61      0.48      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:04<00:00, 20.45s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "## minmax scaler\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('svc', svc),\n",
    "                                ('mp', mp)],\n",
    "                                #('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "\n",
    "# min : 0.3943883380974001\n",
    "# sta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop 안한거 svc -> cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 22%|██▏       | 8/36 [01:05<03:46,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.1, 0.8, 0.1), max_val : 0.514068324623177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.34      0.37       758\n",
      "           1       0.63      0.69      0.66      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.52      0.52      0.51      2000\n",
      "weighted avg       0.54      0.56      0.55      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [04:46<00:00,  7.96s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "## standard scaler\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1, w3 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) for w3 in range(1, 10) if w1 + w2 + w3 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  5%|▌         | 1/19 [00:08<02:33,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.5, 9.5), max_val : 0.5211014666267584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.36      0.38       758\n",
      "           1       0.64      0.68      0.66      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.55      0.56      0.55      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:43<00:00,  8.61s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.5, w2 * 0.5) for w1 in range(1, 20) for w2 in range(1, 20) if w1 + w2 == 20]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                ('mp', mp)],\n",
    "                                #('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=[0.2, 0.8]\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "# max_weigth : (0.2, 0.8), max_val : 0.5211014666267584\n",
    "#  0       0.41      0.36      0.38       758\n",
    "#  1       0.64      0.68      0.66      1242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 44%|████▍     | 4/9 [00:10<00:13,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.4, 0.6000000000000001), max_val : 0.5025363110806268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.36      0.37       758\n",
      "           1       0.62      0.65      0.64      1242\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.50      0.50      0.50      2000\n",
      "weighted avg       0.53      0.54      0.53      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:24<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                #('mp', mp)],\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "# min : 0.5016342043444918\n",
    "# sta : 0.5168004757656854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 예측 수행\n",
    "test_X = test.drop(columns=['user_id'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "test_predictions = voting_model.predict(test_X)\n",
    "\n",
    "# 제출 양식 파일(sample_submission.csv)의 'target' 컬럼에 나의 Test 데이터에 대한 예측 결과로 채우기\n",
    "sample['target'] = test_predictions\n",
    "submit_path = f'./voting_model/voting(cat, xgb)2_tuned_model_drop(aban, ave, pay)_classweight.csv'\n",
    "sample.to_csv(submit_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subscription_duration 0.10698203\n",
      "recent_login_time 0.10118902\n",
      "average_time_per_learning_session 0.10923754\n",
      "monthly_active_learning_days 0.099171825\n",
      "total_completed_courses 0.09464165\n",
      "recent_learning_achievement 0.10586606\n",
      "community_engagement_level 0.10021998\n",
      "preferred_difficulty_level 0.100718796\n",
      "subscription_type 0.08933906\n",
      "customer_inquiry_history 0.092634104\n"
     ]
    }
   ],
   "source": [
    "for i ,j in zip(X_train.columns, voting_model.feature_importances_):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_val : 0.5211014666267584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.36      0.38       758\n",
      "           1       0.64      0.68      0.66      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.55      0.56      0.55      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001d6e9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002c77d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002df5b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000b6068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00184a0c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  target\n",
       "0  0001d6e9       1\n",
       "1  0002c77d       1\n",
       "2  0002df5b       0\n",
       "3  000b6068       1\n",
       "4  00184a0c       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 최대 점수 !!! 0.5330428221\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64'] and col not in ['target']]\n",
    "numerical_cols.remove('payment_pattern')\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object' and col not in ['user_id']]\n",
    "categorical_cols.append('payment_pattern')\n",
    "# 데이터 스케일링을 위한 StandardScaler 인스턴스 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 수치형 데이터에 대해 스케일링 적용\n",
    "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])\n",
    "\n",
    "# 레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "# 전처리 후 학습 데이터 확인\n",
    "train.head()\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = train.drop(columns=['user_id', 'target'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "y = train['target']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "\n",
    "voting_model = VotingClassifier(estimators=\n",
    "                            [('cat', cat),\n",
    "                            ('mp', mp)],\n",
    "                            #('xgb', xgb)],\n",
    "                            voting='soft',\n",
    "                            weights=[0.2, 0.8]\n",
    "\n",
    "                            \n",
    "                            )\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터에서 성능 평가\n",
    "val_predictions = voting_model.predict(X_val)\n",
    "val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "print(f'max_val : {val_f1}')\n",
    "print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "\n",
    "test.drop(columns=['user_id'], inplace=True, axis=1) \n",
    "test_predictions = voting_model.predict(test)\n",
    "\n",
    "# 제출 양식 파일(sample_submission.csv)의 'target' 컬럼에 나의 Test 데이터에 대한 예측 결과로 채우기\n",
    "sample['target'] = test_predictions\n",
    "\n",
    "# 리더보드 제출을 위해 나의 예측 결과를 baseline_submit.csv로 저장\n",
    "submit_path = './voting(cat, mp)_drop(None)_nopreprocessing).csv'\n",
    "sample.to_csv(submit_path, index=False)\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dbswo\\anaconda3\\envs\\subs_predict\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:21:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_val : 0.490144904856496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.28      0.32       758\n",
      "           1       0.62      0.70      0.66      1242\n",
      "\n",
      "    accuracy                           0.55      2000\n",
      "   macro avg       0.49      0.49      0.49      2000\n",
      "weighted avg       0.52      0.55      0.53      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 현재 최대 점수 !!! 0.5330428221\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64'] and col not in ['target']]\n",
    "numerical_cols.remove('payment_pattern')\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object' and col not in ['user_id']]\n",
    "categorical_cols.append('payment_pattern')\n",
    "# 데이터 스케일링을 위한 StandardScaler 인스턴스 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 수치형 데이터에 대해 스케일링 적용\n",
    "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])\n",
    "\n",
    "# 레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "# 전처리 후 학습 데이터 확인\n",
    "train.head()\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = train.drop(columns=['user_id', 'target'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "y = train['target']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=30, max_features='sqrt', min_samples_leaf=3, min_samples_split=2, n_estimators=200, random_state=42, class_weight=weights)\n",
    "gb = GradientBoostingClassifier(learning_rate=1.0, max_depth=4, n_estimators=500, random_state=42, subsample=0.7)\n",
    "svc = SVC(C=100, gamma=0.01, random_state=42, probability=True, class_weight=weights)\n",
    "bgg = BaggingClassifier()\n",
    "hgb = HistGradientBoostingClassifier(l2_regularization=0.1, learning_rate=0.5, max_depth=7, max_iter=300, random_state=42, class_weight=weights, categorical_features=[9, 10, 12])\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5, class_weights=weights)\n",
    "\n",
    "voting_model = VotingClassifier(estimators=\n",
    "                            [\n",
    "                            ('svc', svc),\n",
    "                            ('cat', cat),\n",
    "                            ('mp', mp),\n",
    "                            ('xgb', xgb)],\n",
    "                            voting='soft',\n",
    "                            weights=[1, 2, 2, 2]\n",
    "                      \n",
    "                            )\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 검증 데이터에서 성능 평가\n",
    "val_predictions = voting_model.predict(X_val)\n",
    "val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "print(f'max_val : {val_f1}')\n",
    "print(classification_report(y_val, val_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subs_predict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
