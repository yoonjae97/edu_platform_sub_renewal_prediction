{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.ensemble import BaggingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, KMeansSMOTE, SVMSMOTE, SMOTENC, SMOTEN\n",
    "from imblearn.under_sampling import ClusterCentroids, EditedNearestNeighbours, RepeatedEditedNearestNeighbours, AllKNN, NearMiss, InstanceHardnessThreshold, NeighbourhoodCleaningRule, OneSidedSelection, TomekLinks\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.1411436082813013, 1: 0.8899282419272168}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "y = train['target']\n",
    "\n",
    "train.drop(columns=['user_id', 'target'], axis=1, inplace=True)\n",
    "test.drop(columns=['user_id'], axis=1, inplace=True)\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64']]\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object']\n",
    "# 중요한 변수 설정\n",
    "important_variable = 'average_time_per_learning_session'\n",
    "\n",
    "# 수치형 데이터 및 중요한 변수 분할\n",
    "train_numeric_data = train[numerical_cols]\n",
    "test_numeric_data = test[numerical_cols]\n",
    "\n",
    "\n",
    "# 수치형 파이프라인 구성 (스케일링 및 PCA)\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "])\n",
    "\n",
    "# 변환을 적용하는 ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_pipeline, numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "# 전체 데이터 처리\n",
    "train_numeric_processed_data = preprocessor.fit_transform(train)\n",
    "test_numeric_processed_data = preprocessor.transform(test)\n",
    "\n",
    "#스케일링된 중요한 변수들을 다시 DataFrame에 추가\n",
    "scaler = StandardScaler()\n",
    "train[important_variable] = scaler.fit_transform(train[important_variable].values.reshape(-1, 1))\n",
    "test[important_variable] = scaler.transform(test[important_variable].values.reshape(-1, 1))\n",
    "\n",
    "categorical_cols.append(important_variable)\n",
    "\n",
    "train = pd.concat([\n",
    "    pd.DataFrame(train_numeric_processed_data, columns=['pca1', 'pca2']),  # PCA 컬럼 이름 설정 필요\n",
    "    train[categorical_cols]\n",
    "], axis=1)\n",
    "\n",
    "test = pd.concat([\n",
    "    pd.DataFrame(test_numeric_processed_data, columns=['pca1', 'pca2']),  # PCA 컬럼 이름 설정 필요\n",
    "    test[categorical_cols]\n",
    "], axis=1)\n",
    "\n",
    "train.head()\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y, test_size=0.2, random_state=42)\n",
    "X_train, y_train = OneSidedSelection().fit_resample(X_train, y_train)\n",
    "\n",
    "counts = list(y_train.value_counts())\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop 안한거 svc -> cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 67%|██████▋   | 24/36 [02:00<01:00,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.4, 0.30000000000000004, 0.30000000000000004), max_val : 0.520507639185112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.46      0.43       758\n",
      "           1       0.64      0.59      0.61      1242\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.55      0.54      0.54      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:00<00:00,  5.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "## standard scaler\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1, w3 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) for w3 in range(1, 10) if w1 + w2 + w3 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=8, iterations=500, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate='constant',  learning_rate_init=0.001, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=500, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 89%|████████▉ | 8/9 [00:30<00:03,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.8, 0.2), max_val : 0.5254648450243864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.51      0.45       758\n",
      "           1       0.65      0.55      0.60      1242\n",
      "\n",
      "    accuracy                           0.54      2000\n",
      "   macro avg       0.53      0.53      0.53      2000\n",
      "weighted avg       0.56      0.54      0.54      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:34<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=8, iterations=500, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate='constant',  learning_rate_init=0.001, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=500, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for i in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                ('mp', mp)],\n",
    "                                #('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=i\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {i}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "\n",
    "# (0.2, 0.8) 0.33 / 0.69\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 33%|███▎      | 3/9 [00:13<00:27,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (0.30000000000000004, 0.7000000000000001), max_val : 0.5186430179583381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.47      0.43       758\n",
      "           1       0.64      0.58      0.61      1242\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.55      0.53      0.54      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:39<00:00,  4.40s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.1, w2 * 0.1) for w1 in range(1, 10) for w2 in range(1, 10) if w1 + w2 == 10]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=8, iterations=500, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate='constant',  learning_rate_init=0.001, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=500, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [('cat', cat),\n",
    "                                #('mp', mp)],\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "# min : 0.5016342043444918\n",
    "# sta : 0.5168004757656854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 16%|█▌        | 3/19 [00:05<00:29,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_weigth : (1.5, 8.5), max_val : 0.5150866400145837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.45      0.42       758\n",
      "           1       0.64      0.58      0.61      1242\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.54      0.53      0.54      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:35<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "weights_to_test = [(w1 * 0.5, w2 * 0.5) for w1 in range(1, 20) for w2 in range(1, 20) if w1 + w2 == 20]\n",
    "weights_to_test\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=8, iterations=500, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate='constant',  learning_rate_init=0.001, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=500, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "for weight in tqdm(weights_to_test):\n",
    "    voting_model = VotingClassifier(estimators=\n",
    "                                [#('cat', cat),\n",
    "                                ('mp', mp),\n",
    "                                ('xgb', xgb)],\n",
    "                                voting='soft',\n",
    "                                weights=weight\n",
    "\n",
    "                                \n",
    "                                )\n",
    "\n",
    "    voting_model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에서 성능 평가\n",
    "    val_predictions = voting_model.predict(X_val)\n",
    "    val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    if val_f1 > max_val:\n",
    "        clear_output(wait=True)\n",
    "        print(f'max_weigth : {weight}, max_val : {val_f1}')\n",
    "        print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "        max_val = val_f1\n",
    "        max_weight = weight\n",
    "# min : 0.5016342043444918\n",
    "# sta : 0.5168004757656854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028977</td>\n",
       "      <td>-0.278795</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077895</td>\n",
       "      <td>0.874575</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.914812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.356407</td>\n",
       "      <td>1.056478</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.344479</td>\n",
       "      <td>-0.403076</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.248365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.528107</td>\n",
       "      <td>2.615061</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.831689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pca1      pca2  preferred_difficulty_level  subscription_type  \\\n",
       "0  0.028977 -0.278795                           1                  1   \n",
       "1  0.077895  0.874575                           1                  1   \n",
       "2  0.356407  1.056478                           1                  1   \n",
       "3  0.344479 -0.403076                           1                  1   \n",
       "4 -0.528107  2.615061                           2                  1   \n",
       "\n",
       "   average_time_per_learning_session  \n",
       "0                           0.154226  \n",
       "1                          -0.914812  \n",
       "2                          -0.007198  \n",
       "3                           1.248365  \n",
       "4                          -0.831689  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 예측 수행\n",
    "test_X = test.drop(columns=['user_id'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "test_predictions = voting_model.predict(test_X)\n",
    "\n",
    "# 제출 양식 파일(sample_submission.csv)의 'target' 컬럼에 나의 Test 데이터에 대한 예측 결과로 채우기\n",
    "sample['target'] = test_predictions\n",
    "submit_path = f'./voting_model/voting(cat, xgb)2_tuned_model_drop(aban, ave, pay)_classweight.csv'\n",
    "sample.to_csv(submit_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subscription_duration 0.10698203\n",
      "recent_login_time 0.10118902\n",
      "average_time_per_learning_session 0.10923754\n",
      "monthly_active_learning_days 0.099171825\n",
      "total_completed_courses 0.09464165\n",
      "recent_learning_achievement 0.10586606\n",
      "community_engagement_level 0.10021998\n",
      "preferred_difficulty_level 0.100718796\n",
      "subscription_type 0.08933906\n",
      "customer_inquiry_history 0.092634104\n"
     ]
    }
   ],
   "source": [
    "for i ,j in zip(X_train.columns, voting_model.feature_importances_):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_val : 0.49441982967414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.27      0.32       758\n",
      "           1       0.62      0.73      0.67      1242\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.50      0.50      0.49      2000\n",
      "weighted avg       0.53      0.56      0.54      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001d6e9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002c77d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002df5b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000b6068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00184a0c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  target\n",
       "0  0001d6e9       0\n",
       "1  0002c77d       1\n",
       "2  0002df5b       0\n",
       "3  000b6068       1\n",
       "4  00184a0c       1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 최대 점수 !!! 0.5330428221\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import  CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# train['recent_learning_achievement'] = train['recent_learning_achievement'].apply(lambda x :  train['recent_learning_achievement'].mean() if x  > 100 else x)\n",
    "train['payment_pattern'] = train['recent_learning_achievement'].apply(lambda x: 'continuous' if x in [7, 5, 3, 1] else ('discontinuous' if x in [6, 4, 2] else 'Never'))\n",
    "test['payment_pattern'] = test['recent_learning_achievement'].apply(lambda x: 'continuous' if x in [7, 5, 3, 1] else ('discontinuous' if x in [6, 4, 2] else 'Never'))\n",
    "\n",
    "# test['recent_learning_achievement'] = test['recent_learning_achievement'].apply(lambda x :  train['recent_learning_achievement'].mean() if x  > 100 else x)\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64'] and col not in ['target']]\n",
    "#numerical_cols.remove('payment_pattern')\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object' and col not in ['user_id']]\n",
    "#categorical_cols.append('payment_pattern')\n",
    "# 데이터 스케일링을 위한 StandardScaler 인스턴스 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 수치형 데이터에 대해 스케일링 적용\n",
    "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])\n",
    "\n",
    "# 레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "# 전처리 후 학습 데이터 확인\n",
    "train.head()\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = train.drop(columns=['user_id', 'target'])  # user_id는 제외하고 특성 데이터로 사용\n",
    "y = train['target']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 훈련 데이터를 기반으로 클래스 가중치 계산 \n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=6, iterations=700, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate_init=0.01, solver='adam', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=1.0, max_depth=7, n_estimators=50, random_state=42, subsample=0.5)\n",
    "max_val = 0\n",
    "\n",
    "\n",
    "voting_model = VotingClassifier(estimators=\n",
    "                            [('cat', cat),\n",
    "                            ('mp', mp)],\n",
    "                            #('xgb', xgb)],\n",
    "                            voting='soft',\n",
    "                            weights=[0.2, 0.8]\n",
    "\n",
    "                            \n",
    "                            )\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터에서 성능 평가\n",
    "val_predictions = voting_model.predict(X_val)\n",
    "val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "print(f'max_val : {val_f1}')\n",
    "print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "\n",
    "test.drop(columns=['user_id'], inplace=True, axis=1) \n",
    "test_predictions = voting_model.predict(test)\n",
    "\n",
    "# 제출 양식 파일(sample_submission.csv)의 'target' 컬럼에 나의 Test 데이터에 대한 예측 결과로 채우기\n",
    "sample['target'] = test_predictions\n",
    "\n",
    "# 리더보드 제출을 위해 나의 예측 결과를 baseline_submit.csv로 저장\n",
    "#submit_path = './voting(cat, mp)_drop(None)_nopreprocessing).csv'\n",
    "#sample.to_csv(submit_path, index=False)\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>subscription_duration</th>\n",
       "      <th>recent_login_time</th>\n",
       "      <th>average_login_time</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "      <th>monthly_active_learning_days</th>\n",
       "      <th>total_completed_courses</th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>abandoned_learning_sessions</th>\n",
       "      <th>community_engagement_level</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>customer_inquiry_history</th>\n",
       "      <th>payment_pattern</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00030dc2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.636424</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.941755</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a7fac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.735407</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.752942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001daa99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.903691</td>\n",
       "      <td>0.017473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.254863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0047ee1a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.433492</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.068185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007855db</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.640182</td>\n",
       "      <td>0.045014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.733914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>ffb25bdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.481035</td>\n",
       "      <td>174.327012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.812784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>ffbed767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.962679</td>\n",
       "      <td>174.562720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.074082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>ffc7a476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.279514</td>\n",
       "      <td>176.084277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.385512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>ffcca840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.815833</td>\n",
       "      <td>177.351455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.942927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>fff20cbb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.998490</td>\n",
       "      <td>179.176060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.135153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3801 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  subscription_duration  recent_login_time  average_login_time  \\\n",
       "0     00030dc2                    6.0               27.0            3.636424   \n",
       "1     000a7fac                    NaN                NaN            4.735407   \n",
       "2     001daa99                    NaN                NaN            4.903691   \n",
       "3     0047ee1a                    NaN                NaN            5.433492   \n",
       "4     007855db                    NaN                NaN            5.640182   \n",
       "...        ...                    ...                ...                 ...   \n",
       "3796  ffb25bdf                    NaN                NaN           24.481035   \n",
       "3797  ffbed767                    NaN                NaN           24.962679   \n",
       "3798  ffc7a476                    NaN                NaN           25.279514   \n",
       "3799  ffcca840                    NaN                NaN           25.815833   \n",
       "3800  fff20cbb                    NaN                NaN           26.998490   \n",
       "\n",
       "      average_time_per_learning_session  monthly_active_learning_days  \\\n",
       "0                              0.011515                          18.0   \n",
       "1                              0.012562                           NaN   \n",
       "2                              0.017473                           NaN   \n",
       "3                              0.029555                           NaN   \n",
       "4                              0.045014                           NaN   \n",
       "...                                 ...                           ...   \n",
       "3796                         174.327012                           NaN   \n",
       "3797                         174.562720                           NaN   \n",
       "3798                         176.084277                           NaN   \n",
       "3799                         177.351455                           NaN   \n",
       "3800                         179.176060                           NaN   \n",
       "\n",
       "      total_completed_courses  recent_learning_achievement  \\\n",
       "0                        12.0                    35.941755   \n",
       "1                         NaN                    41.752942   \n",
       "2                         NaN                    42.254863   \n",
       "3                         NaN                    43.068185   \n",
       "4                         NaN                    43.733914   \n",
       "...                       ...                          ...   \n",
       "3796                      NaN                   104.812784   \n",
       "3797                      NaN                   105.074082   \n",
       "3798                      NaN                   106.385512   \n",
       "3799                      NaN                   106.942927   \n",
       "3800                      NaN                   107.135153   \n",
       "\n",
       "      abandoned_learning_sessions  community_engagement_level  \\\n",
       "0                             3.0                         5.0   \n",
       "1                             NaN                         NaN   \n",
       "2                             NaN                         NaN   \n",
       "3                             NaN                         NaN   \n",
       "4                             NaN                         NaN   \n",
       "...                           ...                         ...   \n",
       "3796                          NaN                         NaN   \n",
       "3797                          NaN                         NaN   \n",
       "3798                          NaN                         NaN   \n",
       "3799                          NaN                         NaN   \n",
       "3800                          NaN                         NaN   \n",
       "\n",
       "     preferred_difficulty_level subscription_type  customer_inquiry_history  \\\n",
       "0                           Low             Basic                       1.0   \n",
       "1                           NaN               NaN                       NaN   \n",
       "2                           NaN               NaN                       NaN   \n",
       "3                           NaN               NaN                       NaN   \n",
       "4                           NaN               NaN                       NaN   \n",
       "...                         ...               ...                       ...   \n",
       "3796                        NaN               NaN                       NaN   \n",
       "3797                        NaN               NaN                       NaN   \n",
       "3798                        NaN               NaN                       NaN   \n",
       "3799                        NaN               NaN                       NaN   \n",
       "3800                        NaN               NaN                       NaN   \n",
       "\n",
       "      payment_pattern  target  \n",
       "0                 1.0     0.0  \n",
       "1                 NaN     NaN  \n",
       "2                 NaN     NaN  \n",
       "3                 NaN     NaN  \n",
       "4                 NaN     NaN  \n",
       "...               ...     ...  \n",
       "3796              NaN     NaN  \n",
       "3797              NaN     NaN  \n",
       "3798              NaN     NaN  \n",
       "3799              NaN     NaN  \n",
       "3800              NaN     NaN  \n",
       "\n",
       "[3801 rows x 15 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "train[train['target']==0].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>subscription_duration</th>\n",
       "      <th>recent_login_time</th>\n",
       "      <th>average_login_time</th>\n",
       "      <th>average_time_per_learning_session</th>\n",
       "      <th>monthly_active_learning_days</th>\n",
       "      <th>total_completed_courses</th>\n",
       "      <th>recent_learning_achievement</th>\n",
       "      <th>abandoned_learning_sessions</th>\n",
       "      <th>community_engagement_level</th>\n",
       "      <th>preferred_difficulty_level</th>\n",
       "      <th>subscription_type</th>\n",
       "      <th>customer_inquiry_history</th>\n",
       "      <th>payment_pattern</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00058702</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.366189</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.115562</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Basic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00076619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.375170</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.830979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00109fa1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.483285</td>\n",
       "      <td>0.037657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.430858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00153d57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.870248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0025c0af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.578543</td>\n",
       "      <td>0.060640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.970217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>ff9a0d6e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.100608</td>\n",
       "      <td>444.324058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.102230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>ffb14cb4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.271289</td>\n",
       "      <td>447.095844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.127099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>ffe5da30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.408557</td>\n",
       "      <td>470.289498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.686851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>fff3144f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.125596</td>\n",
       "      <td>490.233443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.219647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>ffff071d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.284396</td>\n",
       "      <td>503.372616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.643828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6199 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  subscription_duration  recent_login_time  average_login_time  \\\n",
       "0     00058702                    4.0                6.0            2.366189   \n",
       "1     00076619                    NaN                NaN            3.375170   \n",
       "2     00109fa1                    NaN                NaN            3.483285   \n",
       "3     00153d57                    NaN                NaN            3.970000   \n",
       "4     0025c0af                    NaN                NaN            4.578543   \n",
       "...        ...                    ...                ...                 ...   \n",
       "6194  ff9a0d6e                    NaN                NaN           25.100608   \n",
       "6195  ffb14cb4                    NaN                NaN           25.271289   \n",
       "6196  ffe5da30                    NaN                NaN           25.408557   \n",
       "6197  fff3144f                    NaN                NaN           26.125596   \n",
       "6198  ffff071d                    NaN                NaN           26.284396   \n",
       "\n",
       "      average_time_per_learning_session  monthly_active_learning_days  \\\n",
       "0                              0.013535                          24.0   \n",
       "1                              0.035931                           NaN   \n",
       "2                              0.037657                           NaN   \n",
       "3                              0.058419                           NaN   \n",
       "4                              0.060640                           NaN   \n",
       "...                                 ...                           ...   \n",
       "6194                         444.324058                           NaN   \n",
       "6195                         447.095844                           NaN   \n",
       "6196                         470.289498                           NaN   \n",
       "6197                         490.233443                           NaN   \n",
       "6198                         503.372616                           NaN   \n",
       "\n",
       "      total_completed_courses  recent_learning_achievement  \\\n",
       "0                        12.0                    36.115562   \n",
       "1                         NaN                    36.830979   \n",
       "2                         NaN                    42.430858   \n",
       "3                         NaN                    42.870248   \n",
       "4                         NaN                    42.970217   \n",
       "...                       ...                          ...   \n",
       "6194                      NaN                   106.102230   \n",
       "6195                      NaN                   108.127099   \n",
       "6196                      NaN                   109.686851   \n",
       "6197                      NaN                   111.219647   \n",
       "6198                      NaN                   112.643828   \n",
       "\n",
       "      abandoned_learning_sessions  community_engagement_level  \\\n",
       "0                             2.0                         5.0   \n",
       "1                             NaN                         NaN   \n",
       "2                             NaN                         NaN   \n",
       "3                             NaN                         NaN   \n",
       "4                             NaN                         NaN   \n",
       "...                           ...                         ...   \n",
       "6194                          NaN                         NaN   \n",
       "6195                          NaN                         NaN   \n",
       "6196                          NaN                         NaN   \n",
       "6197                          NaN                         NaN   \n",
       "6198                          NaN                         NaN   \n",
       "\n",
       "     preferred_difficulty_level subscription_type  customer_inquiry_history  \\\n",
       "0                           Low             Basic                       2.0   \n",
       "1                           NaN               NaN                       NaN   \n",
       "2                           NaN               NaN                       NaN   \n",
       "3                           NaN               NaN                       NaN   \n",
       "4                           NaN               NaN                       NaN   \n",
       "...                         ...               ...                       ...   \n",
       "6194                        NaN               NaN                       NaN   \n",
       "6195                        NaN               NaN                       NaN   \n",
       "6196                        NaN               NaN                       NaN   \n",
       "6197                        NaN               NaN                       NaN   \n",
       "6198                        NaN               NaN                       NaN   \n",
       "\n",
       "      payment_pattern  target  \n",
       "0                 0.0     1.0  \n",
       "1                 NaN     NaN  \n",
       "2                 NaN     NaN  \n",
       "3                 NaN     NaN  \n",
       "4                 NaN     NaN  \n",
       "...               ...     ...  \n",
       "6194              NaN     NaN  \n",
       "6195              NaN     NaN  \n",
       "6196              NaN     NaN  \n",
       "6197              NaN     NaN  \n",
       "6198              NaN     NaN  \n",
       "\n",
       "[6199 rows x 15 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['target']==1].mode()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca 제출용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_val : 0.5056041577484489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.28      0.33       758\n",
      "           1       0.63      0.75      0.68      1242\n",
      "\n",
      "    accuracy                           0.57      2000\n",
      "   macro avg       0.52      0.51      0.51      2000\n",
      "weighted avg       0.54      0.57      0.55      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001d6e9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002c77d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002df5b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000b6068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00184a0c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  target\n",
       "0  0001d6e9       0\n",
       "1  0002c77d       1\n",
       "2  0002df5b       0\n",
       "3  000b6068       1\n",
       "4  00184a0c       1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "train = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8-sig\")\n",
    "test = pd.read_csv(\"./data/test.csv\", encoding=\"utf-8-sig\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "y = train['target']\n",
    "\n",
    "train.drop(columns=['user_id', 'target'], axis=1, inplace=True)\n",
    "test.drop(columns=['user_id'], axis=1, inplace=True)\n",
    "\n",
    "# 수치형 및 범주형 변수 구분\n",
    "numerical_cols = [col for col in train.columns if train[col].dtype in ['int64', 'float64']]\n",
    "categorical_cols = [col for col in train.columns if train[col].dtype == 'object']\n",
    "# 중요한 변수 설정\n",
    "important_variable = 'average_time_per_learning_session'\n",
    "\n",
    "# 수치형 데이터 및 중요한 변수 분할\n",
    "train_numeric_data = train[numerical_cols]\n",
    "test_numeric_data = test[numerical_cols]\n",
    "\n",
    "\n",
    "# 수치형 파이프라인 구성 (스케일링 및 PCA)\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "])\n",
    "\n",
    "# 변환을 적용하는 ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_pipeline, numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#레이블 인코딩을 위한 LabelEncoder 인스턴스 생성 및 적용\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train[col] = label_encoders[col].fit_transform(train[col])\n",
    "    test[col] = label_encoders[col].transform(test[col])\n",
    "\n",
    "# 전체 데이터 처리\n",
    "train_numeric_processed_data = preprocessor.fit_transform(train)\n",
    "test_numeric_processed_data = preprocessor.transform(test)\n",
    "\n",
    "#스케일링된 중요한 변수들을 다시 DataFrame에 추가\n",
    "scaler = StandardScaler()\n",
    "train[important_variable] = scaler.fit_transform(train[important_variable].values.reshape(-1, 1))\n",
    "test[important_variable] = scaler.transform(test[important_variable].values.reshape(-1, 1))\n",
    "\n",
    "categorical_cols.append(important_variable)\n",
    "\n",
    "train = pd.concat([\n",
    "    pd.DataFrame(train_numeric_processed_data, columns=['pca1', 'pca2']),  # PCA 컬럼 이름 설정 필요\n",
    "    train[categorical_cols]\n",
    "], axis=1)\n",
    "\n",
    "test = pd.concat([\n",
    "    pd.DataFrame(test_numeric_processed_data, columns=['pca1', 'pca2']),  # PCA 컬럼 이름 설정 필요\n",
    "    test[categorical_cols]\n",
    "], axis=1)\n",
    "\n",
    "train.head()\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y, test_size=0.2, random_state=42)\n",
    "X_train, y_train = OneSidedSelection().fit_resample(X_train, y_train)\n",
    "\n",
    "counts = list(y_train.value_counts())\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "\n",
    "class_weight  = compute_class_weight( 'balanced' , classes=[ 0 , 1 ], y=y_train)\n",
    "weights = {i: w for i, w in enumerate(class_weight)}\n",
    "\n",
    "cat = CatBoostClassifier(depth=8, iterations=500, learning_rate=0.1, random_state=42, class_weights=weights, verbose=0)\n",
    "mp = MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=100, learning_rate='constant',  learning_rate_init=0.001, solver='sgd', random_state=42)\n",
    "xgb = XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=500, random_state=42, subsample=0.5)\n",
    "\n",
    "voting_model = VotingClassifier(estimators=\n",
    "                            [('cat', cat),\n",
    "                            ('mp', mp)],\n",
    "                            #('xgb', xgb)],\n",
    "                            voting='soft',\n",
    "                            weights=[0.15, 0.85]\n",
    "\n",
    "                            \n",
    "                            )\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터에서 성능 평가\n",
    "val_predictions = voting_model.predict(X_val)\n",
    "val_f1 = f1_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "print(f'max_val : {val_f1}')\n",
    "print(classification_report(y_val, val_predictions, zero_division=0))\n",
    "\n",
    "#test.drop(columns=['user_id'], inplace=True, axis=1) \n",
    "test_predictions = voting_model.predict(test)\n",
    "\n",
    "# 제출 양식 파일(sample_submission.csv)의 'target' 컬럼에 나의 Test 데이터에 대한 예측 결과로 채우기\n",
    "sample['target'] = test_predictions\n",
    "\n",
    "#리더보드 제출을 위해 나의 예측 결과를 baseline_submit.csv로 저장\n",
    "submit_path = './voting(cat, mp)_pca_oss_015085.csv'\n",
    "sample.to_csv(submit_path, index=False)\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subs_predict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
